{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojii embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # sorry for that, I hate this type of red\n",
    "import pandas as pd\n",
    "import emoji\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = str(Path.home())\n",
    "data = pd.read_csv(f\"{home}/emoji_prediction/data/full_df_twi_tg.csv\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unique = data.drop_duplicates(subset=['texts', 'time', 'source'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique emojis unicode\n",
    "emojis = list(emoji.UNICODE_EMOJI.keys())\n",
    "#emojis = [str(e) for e in emojis]\n",
    "unicodes = [e.encode('unicode-escape').decode(\"utf-8\")  for e in emojis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing texts: stemming, Username|URL standartization, decoding emojis to utf\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def getCleanData(df):\n",
    "    '''\n",
    "    so, we get read of RT sign, \n",
    "    standardize URLs and usernames\n",
    "    '''\n",
    "    df['texts'] = df['texts']\\\n",
    "    .apply(lambda x: re.sub(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)\", \"@username\", x))\\\n",
    "    .apply(lambda x: re.sub(r\"([0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}|((news|telnet|nttp|file|http|ftp|https)://)|(www|ftp)[-A-Za-z0-9]*\\\\.)[-A-Za-z0-9\\\\.]+(:[0-9]*)?/[-A-Za-z0-9_\\\\$\\\\.\\\\+\\\\!\\\\*\\\\(\\\\),;:@&=\\\\?/~\\\\#\\\\%]*[^]'\\\\.}>\\\\),\\\\\\\"]\", \n",
    "                         \"URL\", x))\\\n",
    "    .str.replace(\"RT @username\", \"\")\n",
    "    return df\n",
    "\n",
    "def tokenizeData(df):\n",
    "    '''\n",
    "    stemming, tokenization, \n",
    "    getting rid of unnecessary spaces\n",
    "    '''\n",
    "    m = Mystem()\n",
    "    tokenized_texts = df['texts'].apply(lambda x: m.lemmatize(x))\n",
    "    df['texts'] = df['texts'].apply(lambda x: \" \".join(m.lemmatize(x)))\n",
    "    df['texts'] = df['texts'].apply(lambda x: re.sub('\\s+', ' ', x).strip())\n",
    "    return df, tokenized_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191764, 6)\n",
      "CPU times: user 1.96 s, sys: 33.5 ms, total: 2 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_clean = getCleanData(data_unique)\n",
    "print(data_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.6 s, sys: 5.89 s, total: 40.5 s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_clean, tokenized_texts = tokenizeData(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_clean['texts'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–∞—Ö–∞—Ö–∞—Ö —è —Å–µ–≥–æ–¥–Ω—è –≥–∞—Ä—å —Ö–æ—Ç–µ—Ç—å –ø–µ—Ä–µ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –≤–µ—Å—å üòÅ –∂–¥–∞—Ç—å —Å—Ç–æ—Ä–∏–∑–∞ –≤ –∏–Ω—Å—Ç–∞–≥—Ä–∞–º–º–∞',\n",
       " '—Ö–æ—Ä–æ—à–æ üòÇ —è —Ö–∑ —á—Ç–æ —ç—Ç–æ –Ω–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ )',\n",
       " '–≥–∞—Ä–∏ –ø–æ—Ç–µ—Ä –Ω—É üòÅ',\n",
       " '–¥–∞ , —è –ø–æ–Ω–∏–º–∞—Ç—å ) –ø–µ—Ä–µ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å üòÇ —è –¥–∞–≤–Ω–æ –Ω–µ —Å–º–æ—Ç—Ä–µ—Ç—å .. —á—É—è—Ç—å , –ø—Ä–æ–∏–≥—Ä—ã–≤–∞—Ç—å –º—ã üòÇ',\n",
       " 'üòÇ üòÇ üòÇ',\n",
       " '–Ω–∞–¥–æ –±—ã—Ç—å –≤ —Å–∫–æ—Ä—ã–π –≤—Ä–µ–º—è —Å—Ö–æ–¥–∏—Ç—å –≤ –±–∞—Ä—á–∏–∫ üòè',\n",
       " '–Ω–∏—Ö–æ–≤–∞—Ç—å –≤–µ—Å—å —à–∞—Ä–∏—Ç—å üòÇ',\n",
       " '—É —è —Å —Ç—ã —Ñ–æ—Ç–∫–∞ –≤ –≤–∫ —Å—Ç–æ—è—Ç—å , –≤—Å–µ —è –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å —ç—Ç–æ —à—Ç–æ —Ç–≤–æ–π –ø–∞—Ä–∏–Ω—å ü§£ ü§£ ü§£ ü§£ ü§£',\n",
       " 'ü§î –∫–∞–∫–æ–π –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è',\n",
       " 'üòâ']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[900:910]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8335561\n",
      "[('\\U0001f970', 0.6670569777488708), ('üòô', 0.643570601940155), ('üòó', 0.6321011781692505), ('üòç', 0.6316735148429871), ('ü§ó', 0.6129240393638611), ('üòö', 0.5800038576126099), ('‚òª', 0.5588058233261108), ('üëë', 0.5584381222724915), ('üíñ', 0.5571088194847107), ('üíê', 0.5425295233726501)]\n"
     ]
    }
   ],
   "source": [
    "model_CBOW = Word2Vec(texts, size=300, window=3, min_count=4, workers=4)\n",
    "\n",
    "print(model_CBOW.corpus_total_words)\n",
    "print(model_CBOW.wv.most_similar('üòò', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CBOW.save(\"./models/word2vec_CBOW_new.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read existing models\n",
    "model_CBOW = Word2Vec.load(\"./models/word2vec_CBOW_new.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "similars = [{e: model_CBOW.wv.most_similar(e)} for e in emojis if e in model_CBOW.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./similar_emojis_w2v_CBOW_new.json', 'w') as outfile:\n",
    "    json.dump(similars, outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8335561\n",
      "[('üòó', 0.5187710523605347), ('üòΩ', 0.5164458751678467), ('üíò', 0.5115646123886108), ('üòô', 0.5092437267303467), ('ü§ó', 0.5070638060569763), ('üå†', 0.49633532762527466), ('üòö', 0.48668473958969116), ('üíñ', 0.4852866232395172), ('üôã', 0.4819706082344055), ('üêß', 0.47724226117134094)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model_skip = Word2Vec(texts, size=300, window=5, min_count=4, workers=4, sg=1)\n",
    "print(model_skip.corpus_total_words)\n",
    "print(model_skip.wv.most_similar('üòò'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_skip.save(\"./models/word2vec_SkipGram_new.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "similars_skip = [{e: model_skip.wv.most_similar(e)} for e in emojis if e in model_skip.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(0,len(similars_skip)):\n",
    "    e_similar = []\n",
    "    index = list(similars_skip[e].keys())[0]\n",
    "    for i in similars_skip[e][index]:\n",
    "        if i[0] in emojis:\n",
    "            e_similar.append(i)\n",
    "\n",
    "    similars_skip.append({index: e_similar})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./similar_emojis_w2v_SkipGram_new.json', 'w') as outfile:\n",
    "    json.dump(similars_skip, outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering emojis: KMeans, Affinity propagation, DBSCAN\n",
    "\n",
    "### Spoiler: KMeans wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_found = [e for e in emojis if e in model_CBOW.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [model_CBOW.wv[e] for e in emojis if e in model_CBOW.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters=2, The Silhouette Coefficient is 0.4953552484512329\n",
      "For n_clusters=3, The Silhouette Coefficient is 0.48306041955947876\n",
      "For n_clusters=4, The Silhouette Coefficient is 0.4721744656562805\n",
      "For n_clusters=5, The Silhouette Coefficient is 0.44254857301712036\n",
      "For n_clusters=6, The Silhouette Coefficient is 0.44762417674064636\n",
      "For n_clusters=7, The Silhouette Coefficient is 0.4482634663581848\n",
      "For n_clusters=8, The Silhouette Coefficient is 0.34602969884872437\n",
      "For n_clusters=9, The Silhouette Coefficient is 0.36182931065559387\n",
      "For n_clusters=10, The Silhouette Coefficient is 0.4611460566520691\n",
      "For n_clusters=11, The Silhouette Coefficient is 0.434974730014801\n",
      "For n_clusters=12, The Silhouette Coefficient is 0.35358086228370667\n",
      "For n_clusters=13, The Silhouette Coefficient is 0.3629339933395386\n",
      "For n_clusters=14, The Silhouette Coefficient is 0.3535158038139343\n",
      "For n_clusters=15, The Silhouette Coefficient is 0.3471609055995941\n",
      "For n_clusters=16, The Silhouette Coefficient is 0.35812968015670776\n",
      "For n_clusters=17, The Silhouette Coefficient is 0.43122050166130066\n",
      "For n_clusters=18, The Silhouette Coefficient is 0.3628568649291992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "for n_cluster in range(2, 19):\n",
    "    kmeans = KMeans(n_clusters=n_cluster).fit(X)\n",
    "    label = kmeans.labels_\n",
    "    sil_coeff = silhouette_score(X, label, metric='euclidean')\n",
    "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "k_means = KMeans(n_clusters=14, random_state=1)\n",
    "k_means.fit(X)\n",
    "k_means_labels = k_means.labels_ # array with cluster of emojis (concat to df)\n",
    "\n",
    "\n",
    "k_means_labels_unique = np.unique(k_means_labels)\n",
    "k_means_cluster_centers = k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_clusters = pd.DataFrame(k_means_labels, index=emojis_found, columns=['cluster_group']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index\n",
       "cluster_group       \n",
       "0                  5\n",
       "1                567\n",
       "2                 30\n",
       "3                 34\n",
       "4                  2\n",
       "5                 31\n",
       "6                 38\n",
       "7                  2\n",
       "8                 34\n",
       "9                 19\n",
       "10                26\n",
       "11                14\n",
       "12                 5\n",
       "13                 6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_clusters.groupby('cluster_group').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving clusters\n",
    "emo_clusters.to_csv(\"./emo_clusters14.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read saved clusters \n",
    "emo_clusters = pd.read_csv(\"./emo_clusters14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_emojis = emo_clusters[(emo_clusters.cluster_group != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_emojis.to_csv(\"./tsne_emojis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cluster_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>üíî</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>üòñ</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>üòø</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>üò¢</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>üòû</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>üòì</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>üò≠</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>üòî</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>üò£</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>üò•</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>üò™</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>üò´</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>üòí</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>üò©</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  cluster_group\n",
       "113     üíî             11\n",
       "166     üòñ             11\n",
       "187     üòø             11\n",
       "188     üò¢             11\n",
       "210     üòû             11\n",
       "225     üòì             11\n",
       "420     üò≠             11\n",
       "514     üòî             11\n",
       "518     üò£             11\n",
       "614     üò•             11\n",
       "649     üò™             11\n",
       "731     üò´             11\n",
       "756     üòí             11\n",
       "778     üò©             11"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_clusters[emo_clusters.cluster_group == 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top emojis by frequencies in clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_freqs = data[['emoji', 'names']].groupby('emoji').agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emo_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_clusters = pd.merge(emo_freqs, emo_clusters, left_on='emoji', right_on='index')\n",
    "top_freqs_clusters = freqs_clusters.sort_values(by='names', ascending=False).groupby('cluster_group').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_clusters.to_csv(\"./freqs_clusters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_freqs_clusters.to_csv(\"./top_freqs_clusters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>index</th>\n",
       "      <th>cluster_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>3591</td>\n",
       "      <td>üò±</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>3484</td>\n",
       "      <td>üò°</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2412</td>\n",
       "      <td>üò§</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>1811</td>\n",
       "      <td>üò†</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>1755</td>\n",
       "      <td>üëª</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     names index  cluster_group\n",
       "629   3591     üò±              2\n",
       "613   3484     üò°              2\n",
       "616   2412     üò§              2\n",
       "612   1811     üò†              2\n",
       "425   1755     üëª              2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_freqs_clusters[top_freqs_clusters.cluster_group == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Affinity prop and Dbscan for noisy emojis (not succeeding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_1 = emo_clusters['index'][emo_clusters.cluster_group == 1].tolist()\n",
    "\n",
    "clust_1_embed = {}\n",
    "for e in clust_1:\n",
    "    if e in model_CBOW.wv.vocab:\n",
    "        clust_1_embed[e] = model_CBOW.wv[e]\n",
    "        \n",
    "X_clust_1 = list(clust_1_embed.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean silhouette score for Affinity propagation: 0.059873402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "aff = AffinityPropagation(damping=0.9, max_iter=200, convergence_iter=15, copy=True, \n",
    "                                    preference=None, affinity=\"euclidean\", verbose=False)\n",
    "aff_matr = aff.fit_predict(X_clust_1)\n",
    "affinity_labels = aff.labels_\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "mean_sil_aff = silhouette_score(X_clust_1, affinity_labels)\n",
    "\n",
    "print(\"Mean silhouette score for Affinity propagation: \" + str(mean_sil_aff)) # well, emm, hah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 1\n",
      "Estimated number of noise points: 442\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X_clust_1)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_) # father forgive me for i have sinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
